# Journal de bord du projet encadré
## 29/09/25 - Aujourd'hui, en faisant l'exercice 1, j'ai rencontré plusieurs difficultés, que j'ai pu surmonter en faisant divers tests. J'ai par contre eu du mal à compresser le dossier final, étant donné qu'il ne suffit pas de taper la commande zip et le nom du fichier à compresser dans le terminal. J'ai donc cherché sur internet, et demandé à des connaissances qui s'y connaissent plus que moi, et ai ensuite pu terminer l'exercice
## 05/10/25 - Aujourd'hui, j’ai crée un nouveau repository sur git et l’ai cloné sur mon ordinateur. Ensuite, j’ai crée le fichier de ce journal dans git. J’avais déjà écrit une entrée sur un fichier interne, je l’ai donc copiée ci-dessus. En suivant les consignes de l’exercice, après avoir créé le journal de bord, la commande git log ne me donnait pas d’informations comme quoi j’étais en retard par rapport à la version en ligne, et n’ouvrait pas de page de log. J’ai tout de même réitéré la commande git pull pour actualiser mon dossier et avoir accès á ce fichier. 
## 08/10/25 - Lors du cours d'aujourd'hui, Mr. Magistry a survolé bien trop rapidement les concepts dans les scripts, notamment ce qui concerne les arguments et les instructions de contrôle, et je n'y ai rien compris. J'ai pû réaliser les exercices grâce aux explications de certains de mes camarades et à l'aide de ressources en ligne, mais quelques explications suplémentaires ne seraient pas refus.
## 12/10/25 - De ce que je comprends, le script bash de la derniére diapo teste l'argument $"#" pour vérifier qu'il n'est pas égal à 1. Ensuite,  il lit les lignes d'un fichier, qui est donné comme flux d'entrée, et vérifie si elles ressemblent ou non à des URLs. Si oui, il incrémente 1 à la valeur de la variable "OK", et inversément pour la variable "NOK". Une fois que toutes les lignes ont éte lues, la boucle prend fin. Après, la commande echo affiche le nombre d'URLs et de lignes douteuses, en récupérant les valeurs des deux variables citées plus haut.
## 25/10/25 - En faisant les exercices pour le Mini Projet, j'ai eu du mal à transposer les données dans un fichier .tsv. En effet, lors de la récupération du code HTTP, mon script récupérait également un caractère invisble de retour à la ligne (\r ou \n), ce qui séparait donc mes données non seulement par un tab, mais aussi par ce caractère pour ce qui est de la colonne après le code HTTP. J'ai fini par trouver une solution en cherchant sur des forums et autres ressources en ligne. Pour ce qui est de la question 1, voici ma tentative de réponse : On n'utilise pas cat car cette commande affiche nécéssairement le résultat dans le stdout ou dans un fichier dans lequel on redirige celui-ci, tandis que read lit les bytes d'un fichier, ce qui permet de lire le contenu sans l'afficher. Utiliser read permet également d'éviter les boucles infinies. Lorsque j'ai essayé de remplacer read par cat, le script tournait en boucle, et j'ai dũ l'arrêter violemment
## 08/11/25 - En faisant la deuxiéme partie du Mini Projet, j'ai eu plusieurs problèmes. J'ai d'abord essayé de faire en sorte que le programmes s'arrẽte s'il n'y avait pas le nombre requis d'arguments, en rajoutant esle exit à la fin de ma condition, mais en faisant ça, le programme ne tournait plus. J'ai aussi essayé d'ajouter l'option -k ou --insecure à mon curl pour pouvoir surmonter le problème de serveur du site https://roboty.magistry.fr et pouvoir obtenir le code HTTP, l'encodage et le nombre de mots, mais ça n'a pas marché. Par ailleurs, j'ai aussi dû modifié la manière d'obtenir l'encodage de la page, car, pour une raison que je ne comprends pas, ça ne fonctionnait plus pareil que lorsque j'ai fait la première partie du projet.
